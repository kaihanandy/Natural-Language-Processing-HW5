{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf94603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7709ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isChinese(string):\n",
    "    for ch in string:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def init():\n",
    "    lists = []\n",
    "    with open('./translation2019zh/translation2019zh_train.json','r', encoding='utf-8') as dat_f:\n",
    "        data = []\n",
    "        for i,line in enumerate(dat_f):\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if isChinese(data['chinese']) == True:\n",
    "                if len(data['chinese'])<6:\n",
    "                    lists.append(data)\n",
    "                if (len(lists)+1)%100 == 0:\n",
    "                    break\n",
    "    \n",
    "    df = pd.DataFrame(lists)\n",
    "    df.to_csv('datafile.csv', encoding='utf-8', index=False)\n",
    "\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63721051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datafile.csv')\n",
    "df['chinese'] = df['chinese'].apply(lambda x: '@' + x + '。')\n",
    "en_data = df.english.values.tolist()\n",
    "ch_data = df.chinese.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b242b9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "英文:\n",
      " {'t': 0, 'O': 1, '…': 2, 'h': 3, 'i': 4, 'o': 5, 'C': 6, 'U': 7, 'B': 8, 'y': 9, 'z': 10, 'l': 11, 'r': 12, '）': 13, '\"': 14, 'H': 15, 'P': 16, 'T': 17, 'x': 18, 'Y': 19, 'A': 20, '（': 21, '.': 22, \"'\": 23, 'a': 24, ';': 25, 'u': 26, 'p': 27, 'I': 28, '?': 29, 'm': 30, ')': 31, 'w': 32, 'n': 33, 'G': 34, 'f': 35, 'c': 36, 'M': 37, 'J': 38, ',': 39, 'K': 40, '8': 41, 'q': 42, '!': 43, 'E': 44, ' ': 45, '-': 46, 'W': 47, 'S': 48, 'X': 49, 'V': 50, 'b': 51, 'F': 52, 'v': 53, 'R': 54, 'L': 55, 'd': 56, 'e': 57, 'g': 58, 'j': 59, 'k': 60, ':': 61, 'N': 62, '(': 63, 's': 64, 'D': 65, '=': 66}\n",
      "\n",
      "中文\n",
      ": {'引': 0, '爱': 1, '铝': 2, '咱': 3, '晚': 4, '请': 5, '标': 6, '明': 7, '年': 8, '？': 9, '幸': 10, '老': 11, '九': 12, '茄': 13, '为': 14, '类': 15, '市': 16, '：': 17, '她': 18, '器': 19, '架': 20, '法': 21, '尼': 22, '势': 23, '梧': 24, '盐': 25, '线': 26, '洱': 27, '你': 28, '胃': 29, '紧': 30, '二': 31, '迷': 32, '动': 33, '颇': 34, '有': 35, '渍': 36, '母': 37, '祸': 38, '驱': 39, '进': 40, '地': 41, '除': 42, '印': 43, '校': 44, '川': 45, '小': 46, '福': 47, '我': 48, '学': 49, '问': 50, '电': 51, '先': 52, '专': 53, '头': 54, '色': 55, '蒸': 56, '慧': 57, '求': 58, '子': 59, '车': 60, '新': 61, '再': 62, '痛': 63, '铃': 64, '了': 65, '海': 66, '制': 67, '璃': 68, '割': 69, '思': 70, '家': 71, '开': 72, '刷': 73, '船': 74, '做': 75, '偶': 76, '八': 77, '晨': 78, '钱': 79, '乱': 80, '那': 81, '各': 82, '成': 83, '以': 84, '异': 85, '换': 86, '银': 87, '机': 88, '售': 89, '耳': 90, '馊': 91, '剪': 92, '河': 93, '犯': 94, '；': 95, '人': 96, '约': 97, '许': 98, '抱': 99, '楼': 100, '功': 101, '妻': 102, '8': 103, '令': 104, '阿': 105, '拼': 106, '遍': 107, '大': 108, '证': 109, '封': 110, '，': 111, '运': 112, '魁': 113, '对': 114, '浴': 115, '野': 116, '这': 117, '传': 118, '扣': 119, '不': 120, '款': 121, '片': 122, '目': 123, '心': 124, '一': 125, '图': 126, '钛': 127, '保': 128, '知': 129, '办': 130, '松': 131, '多': 132, '采': 133, '清': 134, '着': 135, '他': 136, '灌': 137, '名': 138, '刀': 139, '的': 140, '烤': 141, '肯': 142, '…': 143, '鱼': 144, '几': 145, '退': 146, '今': 147, '摇': 148, '三': 149, '轮': 150, '玻': 151, '算': 152, '该': 153, '坐': 154, '.': 155, '域': 156, '果': 157, '草': 158, '脚': 159, '直': 160, '昨': 161, '?': 162, '和': 163, '智': 164, '品': 165, '艘': 166, '日': 167, '场': 168, '筒': 169, '解': 170, '热': 171, '是': 172, '托': 173, '向': 174, '花': 175, '篮': 176, '什': 177, '君': 178, '如': 179, '踝': 180, '核': 181, '魂': 182, '任': 183, '票': 184, '袭': 185, '嗯': 186, '吗': 187, '看': 188, '康': 189, ' ': 190, '井': 191, '聪': 192, '跳': 193, '应': 194, '雨': 195, '毛': 196, '意': 197, '氧': 198, '铁': 199, '虾': 200, '到': 201, '汤': 202, '然': 203, '铜': 204, '点': 205, '于': 206, '气': 207, '台': 208, '试': 209, '刺': 210, '丝': 211, '泥': 212, '得': 213, '侧': 214, '差': 215, '数': 216, '喝': 217, '街': 218, '！': 219, '蚤': 220, '暴': 221, '很': 222, '发': 223, '导': 224, '春': 225, '谢': 226, '死': 227, '安': 228, '没': 229, '官': 230, '样': 231, '之': 232, '夹': 233, '在': 234, '东': 235, '魔': 236, '位': 237, '讽': 238, '齐': 239, '领': 240, '战': 241, '会': 242, '型': 243, '阒': 244, '撒': 245, '盒': 246, '无': 247, '天': 248, '早': 249, '结': 250, '。': 251, '鸭': 252, '翰': 253, '何': 254, '纯': 255, '水': 256, '方': 257, '您': 258, '季': 259, '前': 260, '怕': 261, '错': 262, '吧': 263, '骨': 264, '包': 265, '密': 266, '手': 267, '@': 268, '上': 269, '哀': 270, '临': 271, '么': 272, '厂': 273, '百': 274, '恳': 275, '化': 276, '将': 277, '单': 278, '深': 279, '个': 280}\n"
     ]
    }
   ],
   "source": [
    "en_vocab = set(''.join(en_data)) # 生成字典\n",
    "id2en = list(en_vocab)\n",
    "en2id = {c:i for i,c in enumerate(id2en)}\n",
    "ch_vocab = set(''.join(ch_data))\n",
    "id2ch = list(ch_vocab)\n",
    "ch2id = {c:i for i,c in enumerate(id2ch)}\n",
    "print('\\n英文:\\n', en2id)\n",
    "print('\\n中文\\n:', ch2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e133c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numData(en2id,ch2id,en_data):\n",
    "    en_num_data = [[en2id[en] for en in line ] for line in en_data]\n",
    "    ch_num_data = [[ch2id[ch] for ch in line] for line in ch_data]\n",
    "    de_num_data = [[ch2id[ch] for ch in line][1:] for line in ch_data]\n",
    "    print('char:', en_data[1])\n",
    "    print('index:', en_num_data[1])\n",
    "    max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
    "    max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
    "    print('max encoder length:', max_encoder_seq_length)\n",
    "    print('max decoder length:', max_decoder_seq_length)\n",
    "    \n",
    "    encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "    \n",
    "    for i in range(len(ch_num_data)):\n",
    "        for t, j in enumerate(en_num_data[i]):\n",
    "            encoder_input_data[i, t, j] = 1.\n",
    "        for t, j in enumerate(ch_num_data[i]):\n",
    "            decoder_input_data[i, t, j] = 1.\n",
    "        for t, j in enumerate(de_num_data[i]):\n",
    "            decoder_target_data[i, t, j] = 1.\n",
    "            \n",
    "    print('index data:\\n', en_num_data[1])\n",
    "    print('one hot data:\\n', encoder_input_data[1])\n",
    "    return encoder_input_data,decoder_input_data,decoder_target_data\n",
    "\n",
    "nd = numData(en2id,ch2id,en_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
